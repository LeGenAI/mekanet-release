<div align="center">

# ğŸš€ MekaNet Quick Start Guide

<img src="https://readme-typing-svg.herokuapp.com?font=Orbitron&size=25&duration=3000&pause=1000&color=4ECDC4&center=true&vCenter=true&width=600&height=50&lines=Get+Started+in+5+Minutes;From+Zero+to+MPN+Classification;AI-Powered+Pathology" alt="Quick Start Typing SVG" />

</div>

---

## ğŸ¯ **What You'll Achieve**

<div align="center">

| â±ï¸ **Time** | ğŸ¯ **Goal** | ğŸ“Š **Result** |
|:---:|:---|:---:|
| **2 minutes** | Installation & Setup | âœ… Ready Environment |
| **1 minute** | Download Models | ğŸ¤– Pre-trained Weights |
| **2 minutes** | Run Demo | ğŸ¥ MPN Classification |

</div>

---

## ğŸ **Prerequisites**

### ğŸ–¥ï¸ **System Check**

```bash
# âœ… Check Python version (3.8+ required)
python --version

# âœ… Check available space (5GB+ required)
df -h

# âœ… Check GPU availability (optional)
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
```

---

## ğŸ“¦ **Step 1: Installation (2 minutes)**

### ğŸš€ **Quick Install**

```bash
# ğŸ”„ Clone the repository
git clone https://github.com/LeGenAI/mekanet-release.git
cd mekanet-release

# ğŸ Create virtual environment (recommended)
python -m venv mekanet_env

# ğŸ”§ Activate environment
# On Windows:
mekanet_env\Scripts\activate
# On macOS/Linux:
source mekanet_env/bin/activate

# ğŸ“¦ Install all dependencies
pip install -r requirements.txt

# ğŸ¯ Install MekaNet package
pip install -e .
```

### ğŸ”§ **Alternative: Manual Install**

<details>
<summary>Click for manual dependency installation</summary>

```bash
# Core ML libraries
pip install torch>=1.9.0 torchvision>=0.10.0
pip install ultralytics>=8.0.0 sahi>=0.11.0

# Data processing
pip install pandas>=1.3.0 numpy>=1.21.0
pip install scikit-learn>=1.0.0 xgboost>=1.5.0

# Computer vision
pip install opencv-python>=4.5.0 Pillow>=8.3.0

# Visualization
pip install matplotlib>=3.4.0 seaborn>=0.11.0

# Scientific computing
pip install scipy>=1.7.0 tqdm>=4.62.0
```

</details>

---

## ğŸ”½ **Step 2: Download Models (1 minute)**

```bash
# ğŸ“ Navigate to weights directory
cd weights

# ğŸ¤– Download pre-trained models
python download_weights.py

# âœ… Verify models are downloaded
ls -la *.pt *.pkl
```

**Expected output:**
```
epoch60.pt      # YOLOv8 detection model (~14MB)
classifier.pkl  # Trained classification model (~2MB)
```

---

## ğŸ§ª **Step 3: Run Your First Demo (2 minutes)**

### ğŸ©º **Binary Classification Demo**

```bash
# ğŸ“ Navigate to experiments
cd ../experiments/classification

# ğŸš€ Run binary classification
python binary_classification.py --data ../../data/demo_data/classification_demo.csv
```

**Expected Output:**
```
ğŸ”¬ Binary Classification Experiment: MPN vs Control
================================================================
ğŸ“Š Dataset Info:
   - Total samples: 20
   - Features: 13 (clinical + morphological)
   - Controls: 10 (Lymphoma cases)
   - MPN cases: 10 (ET, PV, PMF)

ğŸ¤– Training Models:
   âœ… Logistic Regression: 100.0% accuracy
   âœ… Random Forest: 85.0% accuracy
   âœ… Decision Tree: 93.0% accuracy
   âœ… XGBoost: 93.0% accuracy

ğŸ† Best Model: Logistic Regression (100% accuracy)
ğŸ“Š Perfect distinction between MPN patients and controls
```

### ğŸ”¬ **MPN Subtype Classification Demo**

```bash
# ğŸ¯ Run multi-class classification
python mpn_classification.py --data ../../data/demo_data/classification_demo.csv
```

**Expected Output:**
```
ğŸ”¬ Multi-class MPN Classification Experiment
================================================================
ğŸ“Š MPN Subtype Distribution:
   ET (Essential Thrombocythemia): 6 cases (60.0%)
   PV (Polycythemia Vera): 2 cases (20.0%)
   PMF (Primary Myelofibrosis): 2 cases (20.0%)

ğŸ¤– Model Performance:
   âœ… Decision Tree: High accuracy with interpretable rules
   âœ… Random Forest: Robust ensemble performance
   âœ… XGBoost: Advanced gradient boosting results

ğŸ† Best Model: Decision Tree
ğŸ“Š Average recall: 0.90 across all MPN subtypes
```

---

## ğŸ¯ **Quick API Usage**

### ğŸ” **Basic Detection & Classification**

```python
from mekanet import YoloSahiDetector, FeatureExtractor, MPNClassifier
import cv2

# ğŸ¥ Load your bone marrow image
image = cv2.imread('your_BM_image.jpg')

# ğŸ¤– Initialize detector
detector = YoloSahiDetector('weights/epoch60.pt')

# ğŸ” Detect megakaryocytes
detections = detector.predict(image, use_sahi=True)
print(f"Found {len(detections)} megakaryocytes")

# ğŸ“Š Extract features
extractor = FeatureExtractor()
features = extractor.extract_features(detections)

# ğŸ¯ Classify MPN subtype
classifier = MPNClassifier.load('weights/classifier.pkl')
result = classifier.predict_single(list(features.values()))

print(f"ğŸ¥ Diagnosis: {result['predicted_label']}")
print(f"ğŸ“Š Confidence: {result['probability']:.1%}")
```

### ğŸ§¬ **With Clinical Data**

```python
# ğŸ©¸ Patient clinical data
clinical_data = {
    'Age': 65,
    'Hb': 18.7,     # Hemoglobin
    'PLT': 764,     # Platelet count
    'JAK2': 1,      # JAK2 positive
    'CALR': 0,      # CALR negative
    'MPL': 0        # MPL negative
}

# ğŸ”— Combine with morphological features
all_features = list(clinical_data.values()) + list(features.values())

# ğŸ¯ Enhanced classification
result = classifier.predict_single(all_features)
print(f"ğŸ¥ Enhanced Diagnosis: {result['predicted_label']}")
```

---

## ğŸ““ **Interactive Demos**

### ğŸŒ **Jupyter Notebook Demo**

```bash
# ğŸ“ Navigate to notebooks
cd ../notebooks

# ğŸš€ Launch Jupyter
jupyter notebook demo_classification.ipynb
```

**Notebook Features:**
- ğŸ“Š Interactive data exploration
- ğŸ” Feature visualization
- ğŸ¯ Model comparison
- ğŸ“ˆ Performance analysis

---

## ğŸ› ï¸ **Customization Options**

### âš™ï¸ **Detection Parameters**

```python
# ğŸ¯ Customize detection settings
detector = YoloSahiDetector(
    model_path='weights/epoch60.pt',
    confidence_threshold=0.15,  # Lower = more detections
    device='cuda'               # Use GPU if available
)

# ğŸ”¬ SAHI parameters for large images
detections = detector.predict_with_sahi(
    image,
    slice_height=640,           # Tile size
    slice_width=640,
    overlap_height_ratio=0.2,   # Overlap between tiles
    overlap_width_ratio=0.2
)
```

### ğŸ§® **Feature Extraction Options**

```python
# ğŸ“Š Advanced feature extraction
features = extractor.extract_features(
    detections, 
    image_shape=image.shape[:2],  # For density calculations
)

# ğŸ” Access specific feature groups
print("Size features:", features['Avg_Size'], features['Std_Size'])
print("Spatial features:", features['Avg_NND'], features['Num_Clusters'])
```

---

## ğŸš¨ **Troubleshooting**

### âŒ **Common Issues & Solutions**

<details>
<summary>ğŸ› Import errors</summary>

```bash
# ğŸ’¡ Solution: Reinstall dependencies
pip uninstall -y torch torchvision
pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
pip install -r requirements.txt
```

</details>

<details>
<summary>ğŸ”½ Model download fails</summary>

```bash
# ğŸ’¡ Solution: Manual download
cd weights
# Check download_weights.py for placeholder files
# In production, models would be downloaded from releases
```

</details>

<details>
<summary>ğŸ’¾ Out of memory</summary>

```python
# ğŸ’¡ Solution: Reduce image size or use CPU
detector = YoloSahiDetector(
    model_path='weights/epoch60.pt',
    device='cpu'  # Use CPU instead of GPU
)

# Or reduce tile size
detections = detector.predict_with_sahi(
    image,
    slice_height=320,  # Smaller tiles
    slice_width=320
)
```

</details>

<details>
<summary>ğŸ–¼ï¸ Image format issues</summary>

```python
# ğŸ’¡ Solution: Ensure correct image format
import cv2
image = cv2.imread('image.jpg')
if image is None:
    print("âŒ Could not load image")
else:
    print(f"âœ… Image loaded: {image.shape}")
```

</details>

---

## ğŸ¯ **Next Steps**

<div align="center">

| ğŸš€ **Action** | ğŸ“ **Description** | ğŸ”— **Link** |
|:---:|:---|:---:|
| **ğŸ“– Documentation** | Read full documentation | [README.md](../README.md) |
| **ğŸ§ª Advanced Experiments** | Try more complex demos | [experiments/](../experiments/) |
| **ğŸ¥ Clinical Integration** | Learn about clinical use | [Clinical Apps](../README.md#-clinical-applications) |
| **ğŸ¤ Contributing** | Join the community | [Contributing](../README.md#-contributing) |

</div>

---

## ğŸ“ **Get Help**

<div align="center">

### ğŸ†˜ **Need Assistance?**

[![GitHub Issues](https://img.shields.io/badge/GitHub-Issues-red?style=for-the-badge&logo=github)](https://github.com/LeGenAI/mekanet-release/issues)
[![Email Support](https://img.shields.io/badge/Email-Support-blue?style=for-the-badge&logo=gmail)](mailto:jhbaek@sogang.ac.kr)
[![Documentation](https://img.shields.io/badge/Full-Documentation-green?style=for-the-badge&logo=gitbook)](../README.md)

</div>

### ğŸ” **Before Asking for Help**

1. âœ… Check the [troubleshooting section](#-troubleshooting)
2. ğŸ“– Read the [full documentation](../README.md)
3. ğŸ” Search [existing issues](https://github.com/LeGenAI/mekanet-release/issues)
4. ğŸ“‹ Provide system info and error messages

---

<div align="center">

**ğŸ‰ Congratulations! You're now ready to use MekaNet for MPN classification! ğŸ‰**

<img src="https://readme-typing-svg.herokuapp.com?font=Orbitron&size=18&duration=2000&pause=1000&color=4ECDC4&center=true&vCenter=true&width=500&height=40&lines=Ready+to+Transform+Pathology!;Start+Your+AI+Journey+Now!" alt="Success Message" />

</div>